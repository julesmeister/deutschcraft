/**
 * useWebRTCMedia Hook
 * WebRTC implementation with both audio and video support
 * Based on Firebase broadcast signaling
 */

import { useEffect, useRef, useState, useCallback } from 'react';
import { ICE_SERVERS } from './webrtc/config';
import {
  registerParticipant,
  unregisterParticipant,
  updateMuteStatus,
  listenForParticipants,
  sendOffer,
  sendAnswer,
  sendIceCandidate,
  listenForSignals,
  type SignalMessage,
} from './webrtc/firebaseSignaling';
import type { MediaParticipant, UseWebRTCMediaOptions } from './webrtc/types';

interface PeerConnection {
  pc: RTCPeerConnection;
  stream: MediaStream | null;
  audioElement?: HTMLAudioElement;
  videoElement?: HTMLVideoElement;
  gainNode?: GainNode;
  source?: MediaStreamAudioSourceNode;
  analyser?: AnalyserNode;
}

export function useWebRTCMedia({
  roomId,
  userId,
  userName,
  enableVideo = false,
  onError,
}: UseWebRTCMediaOptions) {
  const [isVoiceActive, setIsVoiceActive] = useState(false);
  const [isVideoActive, setIsVideoActive] = useState(false);
  const [isMuted, setIsMuted] = useState(false);
  const [participants, setParticipants] = useState<MediaParticipant[]>([]);
  const [audioStreams, setAudioStreams] = useState<Map<string, MediaStream>>(new Map());
  const [videoStreams, setVideoStreams] = useState<Map<string, MediaStream>>(new Map());
  const [audioAnalysers, setAudioAnalysers] = useState<Map<string, AnalyserNode>>(new Map());

  const localStreamRef = useRef<MediaStream | null>(null);
  const peerConnectionsRef = useRef<Map<string, PeerConnection>>(new Map());
  const audioContextRef = useRef<AudioContext | null>(null);
  const previousRoomIdRef = useRef<string | null>(null);
  const signalUnsubscribeRef = useRef<(() => void) | null>(null);
  const participantsUnsubscribeRef = useRef<(() => void) | null>(null);
  const isMediaActiveRef = useRef<boolean>(false);

  // Reset state when room changes
  useEffect(() => {
    if (previousRoomIdRef.current && previousRoomIdRef.current !== roomId) {
      console.log('[WebRTC Media] Room changed, resetting state');
      cleanup();
    }
    previousRoomIdRef.current = roomId;
  }, [roomId]);

  // Cleanup function
  const cleanup = useCallback(() => {
    // Stop local stream
    if (localStreamRef.current) {
      localStreamRef.current.getTracks().forEach((track) => track.stop());
      localStreamRef.current = null;
    }

    // Close all peer connections
    peerConnectionsRef.current.forEach((peer) => {
      peer.pc.close();
      if (peer.stream) {
        peer.stream.getTracks().forEach((track) => track.stop());
      }
      // Clean up media elements
      if (peer.audioElement) {
        peer.audioElement.pause();
        peer.audioElement.srcObject = null;
      }
      if (peer.videoElement) {
        peer.videoElement.pause();
        peer.videoElement.srcObject = null;
      }
      // Disconnect Web Audio API nodes
      if (peer.source) {
        peer.source.disconnect();
      }
      if (peer.gainNode) {
        peer.gainNode.disconnect();
      }
    });
    peerConnectionsRef.current.clear();

    // Close audio context
    if (audioContextRef.current) {
      audioContextRef.current.close();
      audioContextRef.current = null;
    }

    // Unsubscribe from signals
    if (signalUnsubscribeRef.current) {
      signalUnsubscribeRef.current();
      signalUnsubscribeRef.current = null;
    }

    // Unsubscribe from participants
    if (participantsUnsubscribeRef.current) {
      participantsUnsubscribeRef.current();
      participantsUnsubscribeRef.current = null;
    }

    setIsVoiceActive(false);
    setIsVideoActive(false);
    setIsMuted(false);
    setParticipants([]);
    setAudioStreams(new Map());
    setVideoStreams(new Map());
    setAudioAnalysers(new Map());
    isMediaActiveRef.current = false;
  }, []);

  // Create peer connection for a remote user
  const createPeerConnection = useCallback(
    (remoteUserId: string): RTCPeerConnection => {
      console.log('[WebRTC Media] Creating peer connection for:', remoteUserId);

      const pc = new RTCPeerConnection({
        iceServers: ICE_SERVERS,
        iceCandidatePoolSize: 10,
      });

      // Add local stream tracks
      if (localStreamRef.current) {
        localStreamRef.current.getTracks().forEach((track) => {
          pc.addTrack(track, localStreamRef.current!);
        });
      }

      // Handle ICE candidates
      pc.onicecandidate = async (event) => {
        if (event.candidate) {
          console.log('[WebRTC Media] Sending ICE candidate to:', remoteUserId);
          await sendIceCandidate(roomId, userId, remoteUserId, event.candidate.toJSON());
        }
      };

      // Handle incoming stream
      pc.ontrack = (event) => {
        console.log('[WebRTC Media] ðŸŽµ Received track from:', remoteUserId, 'kind:', event.track.kind);
        const [remoteStream] = event.streams;

        if (remoteStream) {
          const peer = peerConnectionsRef.current.get(remoteUserId);
          if (!peer) {
            console.error('[WebRTC Media] Peer not found for:', remoteUserId);
            return;
          }

          peer.stream = remoteStream;

          // Check if stream has video track
          const hasVideo = remoteStream.getVideoTracks().length > 0;
          const hasAudio = remoteStream.getAudioTracks().length > 0;

          console.log('[WebRTC Media] Stream info:', { hasVideo, hasAudio });

          // Update audio streams
          if (hasAudio) {
            setAudioStreams((prev) => {
              const updated = new Map(prev);
              updated.set(remoteUserId, remoteStream);
              return updated;
            });

            // Setup audio playback
            const audio = new Audio();
            audio.srcObject = remoteStream;
            audio.autoplay = true;
            audio.volume = 1.0;
            audio.play().then(() => {
              console.log('[WebRTC Media] âœ… Audio playing from:', remoteUserId);
            }).catch((err) => {
              console.error('[WebRTC Media] Audio failed:', err);
            });

            peer.audioElement = audio;

            // Web Audio API for analyser
            try {
              if (audioContextRef.current) {
                const source = audioContextRef.current.createMediaStreamSource(remoteStream);
                const analyser = audioContextRef.current.createAnalyser();
                const gainNode = audioContextRef.current.createGain();

                analyser.fftSize = 512;
                analyser.smoothingTimeConstant = 0.8;
                gainNode.gain.value = 1.0;

                source.connect(analyser);
                analyser.connect(gainNode);
                gainNode.connect(audioContextRef.current.destination);

                peer.source = source;
                peer.analyser = analyser;
                peer.gainNode = gainNode;

                setAudioAnalysers((prev) => {
                  const updated = new Map(prev);
                  updated.set(remoteUserId, analyser);
                  return updated;
                });

                console.log('[WebRTC Media] âœ… Audio analyser connected for:', remoteUserId);
              }
            } catch (audioApiError) {
              console.error('[WebRTC Media] Web Audio API setup failed:', audioApiError);
            }
          }

          // Update video streams
          if (hasVideo) {
            setVideoStreams((prev) => {
              const updated = new Map(prev);
              updated.set(remoteUserId, remoteStream);
              return updated;
            });

            console.log('[WebRTC Media] âœ… Video stream ready for:', remoteUserId);
          }
        }
      };

      // Handle connection state
      pc.onconnectionstatechange = () => {
        console.log('[WebRTC Media] Connection state with', remoteUserId, ':', pc.connectionState);

        if (pc.connectionState === 'connected') {
          console.log('[WebRTC Media] âœ… CONNECTED to:', remoteUserId);
        }

        if (pc.connectionState === 'failed' || pc.connectionState === 'disconnected') {
          console.error('[WebRTC Media] âŒ Connection failed/disconnected:', remoteUserId);
          peerConnectionsRef.current.delete(remoteUserId);
        }
      };

      // Handle ICE connection state
      pc.oniceconnectionstatechange = () => {
        console.log('[WebRTC Media] ðŸ§Š ICE state with', remoteUserId, ':', pc.iceConnectionState);
      };

      // Store connection
      peerConnectionsRef.current.set(remoteUserId, { pc, stream: null });

      return pc;
    },
    [roomId, userId]
  );

  // Handle incoming signals
  const handleSignal = useCallback(
    async (signal: SignalMessage) => {
      const { type, fromUserId, data } = signal;

      console.log('[WebRTC Media] Processing signal:', type, 'from:', fromUserId);

      try {
        let peer = peerConnectionsRef.current.get(fromUserId);
        if (!peer) {
          const pc = createPeerConnection(fromUserId);
          peer = { pc, stream: null };
        }

        const { pc } = peer;

        switch (type) {
          case 'offer':
            console.log('[WebRTC Media] Received offer from:', fromUserId);
            await pc.setRemoteDescription(new RTCSessionDescription(data));
            const answer = await pc.createAnswer();
            await pc.setLocalDescription(answer);
            await sendAnswer(roomId, userId, fromUserId, answer);
            console.log('[WebRTC Media] Sent answer to:', fromUserId);
            break;

          case 'answer':
            console.log('[WebRTC Media] Received answer from:', fromUserId);
            await pc.setRemoteDescription(new RTCSessionDescription(data));
            break;

          case 'ice-candidate':
            console.log('[WebRTC Media] Received ICE candidate from:', fromUserId);
            if (data) {
              await pc.addIceCandidate(new RTCIceCandidate(data));
            }
            break;

          case 'participant-joined':
            console.log('[WebRTC Media] Participant joined:', fromUserId);

            if (userId < fromUserId && isMediaActiveRef.current) {
              console.log('[WebRTC Media] âœ… Initiating connection');
              setTimeout(async () => {
                const newPeer = peerConnectionsRef.current.get(fromUserId);
                if (!newPeer) {
                  const pc = createPeerConnection(fromUserId);
                  const offer = await pc.createOffer();
                  await pc.setLocalDescription(offer);
                  await sendOffer(roomId, userId, fromUserId, offer);
                  console.log('[WebRTC Media] âœ… Sent offer to new participant:', fromUserId);
                }
              }, Math.random() * 500);
            }
            break;

          case 'participant-left':
            console.log('[WebRTC Media] Participant left:', fromUserId);
            const leavingPeer = peerConnectionsRef.current.get(fromUserId);
            if (leavingPeer) {
              leavingPeer.pc.close();
              if (leavingPeer.stream) {
                leavingPeer.stream.getTracks().forEach((track) => track.stop());
              }
              peerConnectionsRef.current.delete(fromUserId);

              setAudioStreams((prev) => {
                const updated = new Map(prev);
                updated.delete(fromUserId);
                return updated;
              });

              setVideoStreams((prev) => {
                const updated = new Map(prev);
                updated.delete(fromUserId);
                return updated;
              });

              setAudioAnalysers((prev) => {
                const updated = new Map(prev);
                updated.delete(fromUserId);
                return updated;
              });
            }
            break;
        }
      } catch (error) {
        console.error('[WebRTC Media] Error handling signal:', type, error);
      }
    },
    [roomId, userId, createPeerConnection]
  );

  // Start media (voice and optionally video)
  const startMedia = useCallback(async (withVideo: boolean = false) => {
    try {
      console.log('[WebRTC Media] Starting media...', { roomId, userId, userName, withVideo });

      if (!roomId || !userId) {
        throw new Error('No room ID or user ID provided');
      }

      // Get media stream
      const stream = await navigator.mediaDevices.getUserMedia({
        audio: {
          echoCancellation: true,
          noiseSuppression: true,
          autoGainControl: true,
          sampleRate: 48000,
        },
        video: withVideo ? {
          width: { ideal: 1280 },
          height: { ideal: 720 },
          facingMode: 'user',
          frameRate: { ideal: 30 }
        } : false,
      });

      console.log('[WebRTC Media] Got media stream:', {
        audio: stream.getAudioTracks().length,
        video: stream.getVideoTracks().length
      });

      localStreamRef.current = stream;
      setIsVoiceActive(true);
      setIsVideoActive(withVideo);
      setIsMuted(false);
      isMediaActiveRef.current = true;

      // Enable all tracks
      stream.getTracks().forEach((track) => {
        track.enabled = true;
      });

      // Initialize audio context
      if (!audioContextRef.current) {
        audioContextRef.current = new AudioContext();
      }

      // Register participant
      await registerParticipant(roomId, userId, userName, false);

      // Listen for signals
      signalUnsubscribeRef.current = listenForSignals(roomId, userId, handleSignal);

      // Listen for participants
      participantsUnsubscribeRef.current = listenForParticipants(
        roomId,
        userId,
        (participants) => {
          console.log('[WebRTC Media] Participants updated:', participants.length);
          setParticipants(participants.map(p => ({ ...p, isVideoEnabled: false })));

          // Connect to existing participants
          participants.forEach((participant) => {
            const existingPeer = peerConnectionsRef.current.get(participant.userId);
            if (!existingPeer && userId < participant.userId) {
              setTimeout(async () => {
                const pc = createPeerConnection(participant.userId);
                const offer = await pc.createOffer();
                await pc.setLocalDescription(offer);
                await sendOffer(roomId, userId, participant.userId, offer);
                console.log('[WebRTC Media] âœ… Sent offer to existing participant:', participant.userName);
              }, Math.random() * 1000);
            }
          });
        }
      );

      console.log('[WebRTC Media] âœ… Media started successfully');
    } catch (error) {
      console.error('[WebRTC Media] âŒ Failed to start media:', error);
      setIsVoiceActive(false);
      setIsVideoActive(false);
      onError?.(error as Error);
      throw error;
    }
  }, [roomId, userId, userName, handleSignal, onError, createPeerConnection]);

  // Start voice only
  const startVoice = useCallback(async () => {
    await startMedia(false);
  }, [startMedia]);

  // Start video
  const startVideo = useCallback(async () => {
    await startMedia(true);
  }, [startMedia]);

  // Stop media
  const stopMedia = useCallback(async () => {
    console.log('[WebRTC Media] Stopping media...');

    if (roomId && userId) {
      await unregisterParticipant(roomId, userId);
    }

    cleanup();

    console.log('[WebRTC Media] Media stopped');
    isMediaActiveRef.current = false;
  }, [roomId, userId, cleanup]);

  // Stop voice (alias for stopMedia)
  const stopVoice = useCallback(async () => {
    await stopMedia();
  }, [stopMedia]);

  // Stop video (alias for stopMedia)
  const stopVideo = useCallback(async () => {
    await stopMedia();
  }, [stopMedia]);

  // Toggle mute
  const toggleMute = useCallback(async () => {
    if (!localStreamRef.current) {
      console.warn('[WebRTC Media] Cannot toggle mute - no local stream');
      return false;
    }

    const audioTracks = localStreamRef.current.getAudioTracks();
    if (audioTracks.length === 0) {
      console.warn('[WebRTC Media] Cannot toggle mute - no audio tracks');
      return false;
    }

    const newMutedState = !isMuted;

    audioTracks.forEach((track) => {
      track.enabled = !newMutedState;
    });

    setIsMuted(newMutedState);
    await updateMuteStatus(roomId, userId, userName, newMutedState);

    console.log('[WebRTC Media] Mute toggled:', newMutedState ? 'MUTED' : 'UNMUTED');

    return newMutedState;
  }, [isMuted, roomId, userId, userName]);

  // Toggle video
  const toggleVideo = useCallback(async () => {
    if (!localStreamRef.current) {
      console.warn('[WebRTC Media] Cannot toggle video - no local stream');
      return false;
    }

    const videoTracks = localStreamRef.current.getVideoTracks();

    // If no video tracks, start video
    if (videoTracks.length === 0) {
      console.log('[WebRTC Media] No video tracks - requesting video');
      try {
        const videoStream = await navigator.mediaDevices.getUserMedia({
          video: {
            width: { ideal: 1280 },
            height: { ideal: 720 },
            facingMode: 'user',
            frameRate: { ideal: 30 }
          }
        });

        // Add video tracks to local stream and all peer connections
        videoStream.getVideoTracks().forEach((track) => {
          localStreamRef.current!.addTrack(track);

          // Add to all peer connections
          peerConnectionsRef.current.forEach((peer) => {
            peer.pc.addTrack(track, localStreamRef.current!);
          });
        });

        setIsVideoActive(true);
        console.log('[WebRTC Media] âœ… Video started');
        return true;
      } catch (error) {
        console.error('[WebRTC Media] Failed to start video:', error);
        onError?.(error as Error);
        return false;
      }
    }

    // Toggle existing video tracks
    const newVideoState = !isVideoActive;
    videoTracks.forEach((track) => {
      track.enabled = newVideoState;
    });

    setIsVideoActive(newVideoState);
    console.log('[WebRTC Media] Video toggled:', newVideoState ? 'ON' : 'OFF');

    return newVideoState;
  }, [isVideoActive, roomId, userId, onError]);

  // Get local stream (for video preview)
  const getLocalStream = useCallback(() => {
    return localStreamRef.current;
  }, []);

  // Cleanup on unmount
  useEffect(() => {
    return () => {
      if (localStreamRef.current) {
        stopMedia();
      }
    };
  }, [stopMedia]);

  return {
    isVoiceActive,
    isVideoActive,
    isMuted,
    participants,
    audioStreams,
    videoStreams,
    audioAnalysers,
    localStream: getLocalStream(),
    startVoice,
    startVideo,
    stopVoice,
    stopVideo,
    stopMedia,
    toggleMute,
    toggleVideo,
  };
}
